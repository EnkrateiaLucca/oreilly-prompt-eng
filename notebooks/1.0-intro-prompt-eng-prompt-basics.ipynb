{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Basics\n",
    "\n",
    "A prompt is a piece of text that conveys to a LLM what the user wants. What the user wants can be many things like:\n",
    "\n",
    "- Asking a question\n",
    "- Giving an instruction\n",
    "- Etc...\n",
    "\n",
    "The key components of a prompt are:\n",
    "1. Instruction: where you describe what you want\n",
    "2. Context: additional information to help with performance\n",
    "3. Input data: data the model has not seem to illustrate what you need\n",
    "4. Output indicator: How you prime the model to output what you want, for example asking the model [\"Let's think step by step\" and the end of a prompt can boost reasoning performance](https://arxiv.org/pdf/2201.11903.pdf). You can also write \"Output:\" to prime the model to just write the output and nothing else.\n",
    "\n",
    "[Prompts can also be seen as a form of programming that can customize the outputs and interactions with an LLM.](https://ar5iv.labs.arxiv.org/html/2302.11382#:~:text=prompts%20are%20also%20a%20form%20of%20programming%20that%20can%20customize%20the%20outputs%20and%20interactions%20with%20an%20llm.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"Extract the links from this text:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "In the evolving field of artificial intelligence, recent studies have highlighted the profound impact of large language models (LLMs) on natural language processing capabilities. Smith et al. (2023) in their groundbreaking research, presented in the Journal of AI Research, discussed how the integration of LLMs has revolutionized machine translation, making it significantly more accurate and context-aware (https://www.journalofairesearch.org/integration-of-llms). This leap in technology underscores the need for continuous innovation and ethical considerations in AI development. Additionally, the work by Davis and O'Neil (2024) sheds light on the ethical implications of LLMs in content generation, revealing potential biases that could perpetuate misinformation if not addressed properly (https://www.ethicsinaijournal.org/llm-content-generation-implications).\n",
       "\n",
       "Conversely, initiatives to make LLMs more transparent and accountable have been gaining traction. The OpenAI team's recent publication (2025) in the AI Transparency Review highlights the successful implementation of new algorithms that enhance the interpretability of LLM decisions, thereby making them more reliable and trustworthy (https://www.aitransparencyreview.org/enhancing-llm-interpretability). According to Anderson and Yamamoto (2025), these advancements not only contribute to the reliability of AI systems but also foster a deeper understanding among users, facilitating a more informed and responsible use of AI technologies (https://www.aiuserinsights.org/understanding-ai-decisions). This body of work underscores the dynamic nature of AI research and the collaborative effort required to harness the full potential of LLMs while mitigating associated risks.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = \"\"\"\n",
    "In the evolving field of artificial intelligence, recent studies have highlighted the profound impact of large language models (LLMs) on natural language processing capabilities. Smith et al. (2023) in their groundbreaking research, presented in the Journal of AI Research, discussed how the integration of LLMs has revolutionized machine translation, making it significantly more accurate and context-aware (https://www.journalofairesearch.org/integration-of-llms). This leap in technology underscores the need for continuous innovation and ethical considerations in AI development. Additionally, the work by Davis and O'Neil (2024) sheds light on the ethical implications of LLMs in content generation, revealing potential biases that could perpetuate misinformation if not addressed properly (https://www.ethicsinaijournal.org/llm-content-generation-implications).\n",
    "\n",
    "Conversely, initiatives to make LLMs more transparent and accountable have been gaining traction. The OpenAI team's recent publication (2025) in the AI Transparency Review highlights the successful implementation of new algorithms that enhance the interpretability of LLM decisions, thereby making them more reliable and trustworthy (https://www.aitransparencyreview.org/enhancing-llm-interpretability). According to Anderson and Yamamoto (2025), these advancements not only contribute to the reliability of AI systems but also foster a deeper understanding among users, facilitating a more informed and responsible use of AI technologies (https://www.aiuserinsights.org/understanding-ai-decisions). This body of work underscores the dynamic nature of AI research and the collaborative effort required to harness the full potential of LLMs while mitigating associated risks.\n",
    "\"\"\"\n",
    "\n",
    "Markdown(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def get_response(prompt_question):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful research and programming assistant\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt_question}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are the links extracted from the text:\n",
       "\n",
       "1. https://www.journalofairesearch.org/integration-of-llms\n",
       "2. https://www.ethicsinaijournal.org/llm-content-generation-implications\n",
       "3. https://www.aitransparencyreview.org/enhancing-llm-interpretability\n",
       "4. https://www.aiuserinsights.org/understanding-ai-decisions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = instruction + input_data\n",
    "\n",
    "output = get_response(prompt)\n",
    "\n",
    "Markdown(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Data & Context Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"You are a url extraction engine. You will be fed text and return ONLY a list containing all the urls in the text.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You are a url extraction engine. You will be fed text and return ONLY a list containing all the urls in the text.\n",
       "\n",
       "Extract the links from this text:\n",
       "\n",
       "In the evolving field of artificial intelligence, recent studies have highlighted the profound impact of large language models (LLMs) on natural language processing capabilities. Smith et al. (2023) in their groundbreaking research, presented in the Journal of AI Research, discussed how the integration of LLMs has revolutionized machine translation, making it significantly more accurate and context-aware (https://www.journalofairesearch.org/integration-of-llms). This leap in technology underscores the need for continuous innovation and ethical considerations in AI development. Additionally, the work by Davis and O'Neil (2024) sheds light on the ethical implications of LLMs in content generation, revealing potential biases that could perpetuate misinformation if not addressed properly (https://www.ethicsinaijournal.org/llm-content-generation-implications).\n",
       "\n",
       "Conversely, initiatives to make LLMs more transparent and accountable have been gaining traction. The OpenAI team's recent publication (2025) in the AI Transparency Review highlights the successful implementation of new algorithms that enhance the interpretability of LLM decisions, thereby making them more reliable and trustworthy (https://www.aitransparencyreview.org/enhancing-llm-interpretability). According to Anderson and Yamamoto (2025), these advancements not only contribute to the reliability of AI systems but also foster a deeper understanding among users, facilitating a more informed and responsible use of AI technologies (https://www.aiuserinsights.org/understanding-ai-decisions). This body of work underscores the dynamic nature of AI research and the collaborative effort required to harness the full potential of LLMs while mitigating associated risks.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = context + \"\\n\\n\" + instruction + \"\\n\" + text\n",
    "\n",
    "Markdown(prompt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is the list of URLs extracted from the provided text:\n",
       "1. https://www.journalofairesearch.org/integration-of-llms\n",
       "2. https://www.ethicsinaijournal.org/llm-content-generation-implications\n",
       "3. https://www.aitransparencyreview.org/enhancing-llm-interpretability\n",
       "4. https://www.aiuserinsights.org/understanding-ai-decisions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = get_response(prompt)\n",
    "\n",
    "Markdown(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_indicator = \"Output:\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = context + \"\\n\\n\" + instruction + \"\\n\" + input_data + \"\\n\" + output_indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You are a url extraction engine. You will be fed text and return ONLY a list containing all the urls in the text.\n",
       "\n",
       "Extract the links from this text:\n",
       "\n",
       "In the evolving field of artificial intelligence, recent studies have highlighted the profound impact of large language models (LLMs) on natural language processing capabilities. Smith et al. (2023) in their groundbreaking research, presented in the Journal of AI Research, discussed how the integration of LLMs has revolutionized machine translation, making it significantly more accurate and context-aware (https://www.journalofairesearch.org/integration-of-llms). This leap in technology underscores the need for continuous innovation and ethical considerations in AI development. Additionally, the work by Davis and O'Neil (2024) sheds light on the ethical implications of LLMs in content generation, revealing potential biases that could perpetuate misinformation if not addressed properly (https://www.ethicsinaijournal.org/llm-content-generation-implications).\n",
       "\n",
       "Conversely, initiatives to make LLMs more transparent and accountable have been gaining traction. The OpenAI team's recent publication (2025) in the AI Transparency Review highlights the successful implementation of new algorithms that enhance the interpretability of LLM decisions, thereby making them more reliable and trustworthy (https://www.aitransparencyreview.org/enhancing-llm-interpretability). According to Anderson and Yamamoto (2025), these advancements not only contribute to the reliability of AI systems but also foster a deeper understanding among users, facilitating a more informed and responsible use of AI technologies (https://www.aiuserinsights.org/understanding-ai-decisions). This body of work underscores the dynamic nature of AI research and the collaborative effort required to harness the full potential of LLMs while mitigating associated risks.\n",
       "\n",
       "Output:\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "['https://www.journalofairesearch.org/integration-of-llms', 'https://www.ethicsinaijournal.org/llm-content-generation-implications', 'https://www.aitransparencyreview.org/enhancing-llm-interpretability', 'https://www.aiuserinsights.org/understanding-ai-decisions']"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = get_response(prompt)\n",
    "\n",
    "Markdown(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def get_num_tokens(prompt, model=\"gpt-4-turbo-preview\"):\n",
    "    \"\"\"Calculates the number of tokens in a text prompt\"\"\"\n",
    "    enc = tiktoken.encoding_for_model(model)\n",
    "    return len(enc.encode(prompt))\n",
    "\n",
    "get_num_tokens(instruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering Strategies\n",
    "\n",
    "- Strategy 1: Write clear instructions\n",
    "- Strategy 2: Provide reference text\n",
    "- Strategy 3: Break tasks into subtasks\n",
    "- Strategy 4: Give the model time to think\n",
    "- Strategy 5: Use external tools\n",
    "- Strategy 6: Test changes systematically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_instructions_prompt = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_text_prompt = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_breakdown_prompt = \"\"\"The following is a paper explaining this architecture named 'Transformer':\n",
    "'''\n",
    "'''\n",
    "1. Break this paper down into its main sections.\n",
    "2. Summarize each section in one sentence.\n",
    "3. Write a pargraph combining these summarizations\n",
    "4. Your output should be both the paragraph summary and the bullet points section summary.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_to_think_prompt = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_tools_prompt = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_changes_systematically_prompt = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Is Prompting Hard?\n",
    "\n",
    "1. People don't know what they want\n",
    "2. People know what they want but can't explain it well to the model\n",
    "3. People know what they want but don't know how to get the best performance from the model\n",
    "\n",
    "[Principles for Prompt Engineering by Karina Nguyen](https://youtu.be/6d60zVdcCV4?list=PLcfpQ4tk2k0U3Nr2KKWJsVnjF5S9bTXY-&t=126)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do We Solve This?\n",
    "\n",
    "1. Figure out what you want -> define the task clearly\n",
    "\n",
    "2. Stablish a metric to score the output performance on your tasks\n",
    "\n",
    "3. Experimentation (this is where prompt engineering comes alive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final notes\n",
    "\n",
    "Prompt Engineering is a trial-and-error process that also relies on your intuition.\n",
    "\n",
    "\n",
    "Build domain understanding - use your domain expertise to customize prompt for relevance.\n",
    "\n",
    "\n",
    "Build model understanding - adapt prompt to suit model strengths & weaknesses to improve quality.\n",
    "\n",
    "Iterate & Validate - define acceptance or termination criteria so you iterate to meet expectations but don't over-engineer the prompt to reduce reusability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- [A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT](https://ar5iv.labs.arxiv.org/html/2302.11382)\n",
    "- [Prompt-Engineering-Guide](https://github.com/dair-ai/Prompt-Engineering-Guide)\n",
    "- [A Survey of Large Language Models](https://arxiv.org/pdf/2303.18223.pdf)\n",
    "- [Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing](https://arxiv.org/pdf/2107.13586.pdf)\n",
    "- [prompt engineering guide - zero shot prompting example](https://www.promptingguide.ai/techniques/zeroshot)\n",
    "- [Finetuned language models are zero-shot learners](https://arxiv.org/pdf/2109.01652.pdf)\n",
    "- [prompt engineering guide - few shot prompting](https://www.promptingguide.ai/techniques/fewshot)\n",
    "- [prompt engineering guide - chain of thought prompting](https://www.promptingguide.ai/techniques/cot)\n",
    "- [Wei et al. (2022)](https://arxiv.org/abs/2201.11903)\n",
    "- [prompt engineering guide - self-consistency](https://www.promptingguide.ai/techniques/consistency)\n",
    "- [prompt engineering guide - generate knowledge](https://www.promptingguide.ai/techniques/knowledge)\n",
    "- [Liu et al. 2022](https://arxiv.org/pdf/2110.08387.pdf)\n",
    "- [prompt engineering guide - tree of thoughts (ToT)](https://www.promptingguide.ai/techniques/tot)\n",
    "- [Prompt Engineering by Lilian Weng](https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/)\n",
    "- [Prompt Engineering vs. Blind Prompting](https://mitchellh.com/writing/prompt-engineering-vs-blind-prompting#the-demonstration-set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-env",
   "language": "python",
   "name": "oreilly-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
